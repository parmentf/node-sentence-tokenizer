{
  "name": "sentence-tokenizer",
  "version": "1.0.1",
  "description": "Tokenize paragraphs into sentences, and smaller tokens.",
  "main": "lib/tokenizer.js",
  "scripts": {
    "lint": "eslint lib",
    "test": "mocha",
    "test:w": "mocha -w",
    "build": "tsc",
    "build:w":  "tsc --watch",
    "pretest": "npm run build",
    "prepublish": "npm run build",
    "postversion": "git push && git push --tags"
  },
  "homepage": "http://github.com/parmentf/node-sentence-tokenizer",
  "repository": {
    "type": "git",
    "url": "https://github.com/parmentf/node-sentence-tokenizer.git"
  },
  "keywords": [
    "tokenizer",
    "sentence"
  ],
  "author": "Fran√ßois Parmentier",
  "license": "MIT",
  "readmeFilename": "README.md",
  "dependencies": {
    "debug": "4.1.0"
  },
  "devDependencies": {
    "@types/node": "10.12.11",
    "eslint": "5.9.0",
    "mocha": "5.2.0",
    "typescript": "3.2.1"
  }
}
